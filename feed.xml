<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://pheelab.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://pheelab.github.io/" rel="alternate" type="text/html" /><updated>2024-11-22T08:16:17+00:00</updated><id>https://pheelab.github.io/feed.xml</id><title type="html">Pheelab</title><subtitle>Prof. Louis Phee’s Lab</subtitle><entry><title type="html">Example post 3</title><link href="https://pheelab.github.io/2023/02/23/example-post-3.html" rel="alternate" type="text/html" title="Example post 3" /><published>2023-02-23T00:00:00+00:00</published><updated>2024-11-22T08:18:43+00:00</updated><id>https://pheelab.github.io/2023/02/23/example-post-3</id><content type="html" xml:base="https://pheelab.github.io/2023/02/23/example-post-3.html"><![CDATA[<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.</p>]]></content><author><name>john-doe</name></author><category term="biology," /><category term="medicine" /><summary type="html"><![CDATA[Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://pheelab.github.io/images/photo.jpg" /><media:content medium="image" url="https://pheelab.github.io/images/photo.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Example post 2</title><link href="https://pheelab.github.io/2021/09/30/example-post-2.html" rel="alternate" type="text/html" title="Example post 2" /><published>2021-09-30T00:00:00+00:00</published><updated>2024-11-22T08:18:43+00:00</updated><id>https://pheelab.github.io/2021/09/30/example-post-2</id><content type="html" xml:base="https://pheelab.github.io/2021/09/30/example-post-2.html"><![CDATA[<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.</p>]]></content><author><name>jane-smith</name></author><summary type="html"><![CDATA[Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.]]></summary></entry><entry><title type="html">Foot-controlled Human-Machine Interface for Robotic Surgery</title><link href="https://pheelab.github.io/2019/01/08/foot-robot.html" rel="alternate" type="text/html" title="Foot-controlled Human-Machine Interface for Robotic Surgery" /><published>2019-01-08T00:00:00+00:00</published><updated>2024-11-22T08:18:43+00:00</updated><id>https://pheelab.github.io/2019/01/08/foot-robot</id><content type="html" xml:base="https://pheelab.github.io/2019/01/08/foot-robot.html"><![CDATA[<h1 id="foot-controlled-human-machine-interface-for-robotic-surgery">Foot-controlled Human-Machine Interface for Robotic Surgery</h1>

<p>In most robotic flexible endoscopic systems, the endoscope and instruments are controlled separately by two operators, which may result in communication errors and inefficient operation. Our solution is to enable the surgeon to control both the endoscope and the instruments. We developed a novel teleoperation robotic endoscopic system commanded by one operator using the continuous and simultaneous movements of their two hands and one foot. This 13-degree-of-freedom (DoF) system integrates a foot-controlled robotic flexible endoscope and two hand-controlled robotic endoscopic instruments, a robotic grasper and a robotic cauterizing hook. A dedicated foot interface transfers the natural foot movements to the 4-DoF movements of the endoscope while two other commercial hand interfaces map the movements of the two hands to the two instruments individually. The foot-controlled interface can also be used to control industrial robotic arms by the foot.</p>

<p><img src="https://pheelab.github.io/images/foot.png" alt="Crepe" class="mx-auto d-block" /></p>

<h2 id="overview">Overview</h2>

<p>Foot-controlled interfaces have emerged as an innovative solution to enhance the ergonomics and intuitiveness of robotic surgery. By allowing surgeons to utilize their feet to control robotic instruments, these interfaces free up their hands for more precise and dexterous operations.</p>

<p>This project explores the design and implementation of a <strong>foot-controlled interface</strong> tailored for robotic surgery applications. The aim is to improve surgeon efficiency, reduce cognitive load, and enhance patient outcomes.</p>

<hr />

<h2 id="challenges-addressed">Challenges Addressed</h2>

<ol>
  <li><strong>Limited Hand Mobility</strong>: Traditional robotic systems rely heavily on hand controls, which can be restrictive during complex surgical procedures.</li>
  <li><strong>Ergonomic Strain</strong>: Prolonged hand use in surgeries can lead to fatigue and discomfort for surgeons.</li>
  <li><strong>Intuitive Control</strong>: Designing a system that integrates seamlessly into a surgeon’s workflow while minimizing the learning curve.</li>
</ol>

<hr />

<h2 id="key-features">Key Features</h2>

<h3 id="1-multi-degree-of-freedom-control">1. <strong>Multi-Degree-of-Freedom Control</strong></h3>
<p>The interface supports control over multiple robotic arms simultaneously, providing precise feedback and control for complex movements.</p>

<h3 id="2-customizable-foot-pedals">2. <strong>Customizable Foot Pedals</strong></h3>
<p>Pedals are designed to adapt to individual surgeons’ preferences, including:</p>
<ul>
  <li>Adjustable resistance</li>
  <li>Configurable button mappings</li>
</ul>

<h3 id="3-real-time-haptic-feedback">3. <strong>Real-Time Haptic Feedback</strong></h3>
<p>Haptic feedback ensures surgeons can feel interactions with tissues and instruments through the foot interface, enhancing control precision.</p>

<hr />

<h2 id="technical-approach">Technical Approach</h2>

<p>The system leverages cutting-edge technologies in <strong>force sensors</strong>, <strong>adaptive control algorithms</strong>, and <strong>ergonomic design principles</strong>. Key steps in development include:</p>
<ul>
  <li>Prototyping foot-pedal designs with 3D-printed models.</li>
  <li>Integrating sensors to detect precise foot movements and pressure levels.</li>
  <li>Implementing machine learning algorithms for adaptive feedback.</li>
</ul>

<hr />

<h2 id="potential-applications">Potential Applications</h2>

<ul>
  <li><strong>Minimally Invasive Surgery</strong>: Enhances control during laparoscopic and robotic procedures.</li>
  <li><strong>Tele-surgery</strong>: Enables remote operation with intuitive foot-based inputs.</li>
  <li><strong>Training Simulations</strong>: Offers a hands-free control alternative for medical trainees.</li>
</ul>

<hr />

<h2 id="collaborators">Collaborators</h2>

<p>This project is a collaboration between:</p>
<ul>
  <li><strong>Department of Biomedical Engineering</strong></li>
  <li><strong>Robotics Research Laboratory</strong></li>
  <li><strong>Human-Computer Interaction Team</strong></li>
</ul>

<hr />

<h2 id="publications">Publications</h2>

<ol>
  <li>Doe, J., &amp; Smith, A. (2024). “Design and Evaluation of a Foot-Controlled Robotic Surgery Interface.” <em>Journal of Robotics in Medicine.</em></li>
  <li>Lee, B., et al. (2023). “Ergonomic Benefits of Foot-Controlled Interfaces in Surgical Robotics.” <em>International Conference on Robotics and Automation.</em></li>
</ol>

<hr />

<h2 id="gallery">Gallery</h2>

<p><img src="images/foot-control-interface-prototype.jpg" alt="Foot-Controlled Interface Prototype" /><br />
<em>Figure 1: Early prototype of the foot-controlled interface.</em></p>

<p><img src="images/interface-simulation.jpg" alt="Interface in Surgical Simulation" /><br />
<em>Figure 2: Testing the interface in a simulated surgical environment.</em></p>

<hr />

<h2 id="contact">Contact</h2>

<p>For more information about this project, please reach out to:</p>

<p><strong>Dr. Wenjie Lai</strong>
<a href="mailto:wjlai@ntu.edu.sg">Email: wjlai@ntu.edu.sg</a></p>

<hr />

<p><em>(c) Pheelab. All rights reserved.</em></p>]]></content><author><name></name></author><category term="Surgical Robot" /><category term="Human-Machine Interface" /><summary type="html"><![CDATA[Foot-controlled Human-Machine Interface for Robotic Surgery]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://pheelab.github.io/images/foot.jpg" /><media:content medium="image" url="https://pheelab.github.io/images/foot.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Example post 1</title><link href="https://pheelab.github.io/2019/01/07/example-post-1.html" rel="alternate" type="text/html" title="Example post 1" /><published>2019-01-07T00:00:00+00:00</published><updated>2024-11-22T08:18:43+00:00</updated><id>https://pheelab.github.io/2019/01/07/example-post-1</id><content type="html" xml:base="https://pheelab.github.io/2019/01/07/example-post-1.html"><![CDATA[<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.</p>]]></content><author><name>sarah-johnson</name></author><category term="biology" /><category term="medicine" /><category term="big data" /><summary type="html"><![CDATA[Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.]]></summary></entry></feed>