<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://pheelab.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://pheelab.github.io/" rel="alternate" type="text/html" /><updated>2024-11-28T07:44:11+00:00</updated><id>https://pheelab.github.io/feed.xml</id><title type="html">Pheelab</title><subtitle>Prof. Louis Phee’s Lab</subtitle><entry><title type="html"></title><link href="https://pheelab.github.io/2024/11/28/2022-01-06-trimanipulation.html" rel="alternate" type="text/html" title="" /><published>2024-11-28T07:44:11+00:00</published><updated>2024-11-28T07:46:40+00:00</updated><id>https://pheelab.github.io/2024/11/28/2022-01-06-trimanipulation</id><content type="html" xml:base="https://pheelab.github.io/2024/11/28/2022-01-06-trimanipulation.html"><![CDATA[<figure class="figure">
  <img src="https://pheelab.github.io/images/trimanipulation.jpg" alt="trimanipulation" />
</figure>

<p>Many teleoperation tasks require three or more tools working together, which need the cooperation of multiple operators. The effectiveness of such schemes may be limited by communication issues between individuals. Trimanipulation by a single operator using an artificial third arm controlled together with their natural arms may address this issue. Foot-controlled interfaces have previously shown the capability to be used for the continuous control of robot arms. However, the use of such interfaces for controlling a supernumerary robotic limb in coordination with the natural limbs is not well understood. In this paper, a teleoperation task imitating physically-coupled hands in a virtual reality scene was conducted with 14 subjects to evaluate human performance during trimanipulation. The participants were required to move three limbs together in a coordinated way mimicking three arms holding a shared physical object. It was found that after a short practice session, three-hand trimanipulation with a single subject’s hands and foot was still slower than dyad operation. However, they displayed similar performance in their success rate and higher motion efficiency than two people cooperating.</p>

<h3 id="related-pubulication">Related Pubulication:</h3>

<p class="box-note"><strong>Paper:</strong> Huang, Yanpei et al. Trimanipulation: Evaluation of human performance in a 3-handed coordination task.” <a href="https://doi.org/10.1109/SMC52423.2021.9659027">2021 IEEE international conference on systems, Man, and cybernetics (SMC). IEEE, 2021.</a></p>

<hr />
<p><em>(c)  Pheelab. All rights reserved.</em></p>]]></content><author><name></name></author></entry><entry><title type="html">A Detachable FBG-Based Contact Force Sensor for Capturing Gripper-Vegetable Interactions</title><link href="https://pheelab.github.io/2024/08/08/FBG-Gripper.html" rel="alternate" type="text/html" title="A Detachable FBG-Based Contact Force Sensor for Capturing Gripper-Vegetable Interactions" /><published>2024-08-08T00:00:00+00:00</published><updated>2024-11-28T07:46:40+00:00</updated><id>https://pheelab.github.io/2024/08/08/FBG-Gripper</id><content type="html" xml:base="https://pheelab.github.io/2024/08/08/FBG-Gripper.html"><![CDATA[<figure class="figure">
  <img src="https://pheelab.github.io/images/fbggripper.jpg" alt="fbggripper" />
</figure>

<p>Vertical farming, a sustainable key for urban agriculture, has garnered attention for its land use optimization and enhanced food production capabilities. The adoption of automation in vertical farming is a pivotal response to labor shortages, addressing the need for increased efficiency, particularly in labor-intensive tasks like harvesting. Although soft robotic grippers offer a significant promise for delicately handling fragile objects, the absence of sensors has hindered their full potential to execute precise and secure grasping. To address this challenge, we present a new solution: a detachable Fiber Bragg Grating-based flexible contact force sensor to capture gripper-vegetable interactions. The sensing module was 3D printed using soft material, and the FBG fiber was attached to the module using epoxy. From evaluation tests, this lightweight sensor demonstrated a wide measurement range of up to 9.87 N, with a high sensitivity of 141.7 pm/N, good repeatability, and a hysteresis of 7.96%. Compared to commercial load cells, our sensor achieves a small measurement RMSE of 0.41 N and a percentage error of 4.15%. The sensor was integrated into two robotic 3D-printed soft grippers to enable real-time monitoring of dynamic contact force during vegetable harvesting in vertical farming scenarios. By reflecting contact status, this sensor provides a promising glimpse into the future of agricultural automation, enhancing operational efficiency and strengthening situation awareness and decision-making capabilities in vertical farms. Beyond agriculture, the versatility of this sensor extends to application in areas such as warehousing, logistics, and the food and beverage industry.</p>

<h3 id="related-pubulication">Related Pubulication:</h3>

<p class="box-note"><strong>Paper:</strong> Lai, Wenjie, et al. “A Detachable FBG-Based Contact Force Sensor for Capturing Gripper-Vegetable Interactions.” <a href="https://doi.org/10.1109/ICRA57147.2024.10611433">2024 IEEE 7th International Conference on Soft Robotics (RoboSoft). IEEE, 2024.</a></p>

<hr />
<p><em>(c)  Pheelab. All rights reserved.</em></p>]]></content><author><name>Wenjie Lai</name></author><category term="Soft Robotics" /><category term="Force Sensor" /><summary type="html"><![CDATA[]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://pheelab.github.io/images/fbggripper.jpg" /><media:content medium="image" url="https://pheelab.github.io/images/fbggripper.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Smart Grow-and-Twine Gripper for Vegetable Harvesting in Vertical Farms</title><link href="https://pheelab.github.io/2024/05/13/grow-twine.html" rel="alternate" type="text/html" title="Smart Grow-and-Twine Gripper for Vegetable Harvesting in Vertical Farms" /><published>2024-05-13T00:00:00+00:00</published><updated>2024-11-28T07:46:40+00:00</updated><id>https://pheelab.github.io/2024/05/13/grow-twine</id><content type="html" xml:base="https://pheelab.github.io/2024/05/13/grow-twine.html"><![CDATA[<figure class="figure">
  <img src="https://pheelab.github.io/images/growtwine.jpg" alt="growtwine" />
</figure>

<p>Vertical farming has emerged as a sustainable, efficient, and climate-resilient food production method, which can improve food security. In most commercial vertical farms, harvesting is carried out manually, which are labor-intensive and costly. Numerous robotic grippers solutions have been developed for harvesting. However, they have limitations like restricted adaptivity, excessive mechanical stress on target, and poor accessibility, hindering their adoption for harvesting. Here, we present a tendon-driven gripper equipped with a capacitance-based contact sensor array. The proposed gripper can grow and twine around the target vegetable and adjust the tightness of its grip based on number of contacts. The proposed gripper can generate 4 to 10 N pulling force on bok choy and can also grip various gourds, leafy and podded vegetables. This work paves the way for harvesting automation in vertical farms. Apart from agriculture field, the smart gripper can also be used to grasp objects with various size, shape and weight in warehouse, and food &amp; beverage industry.</p>

<h3 id="related-pubulication">Related Pubulication:</h3>

<p class="box-note"><strong>Paper:</strong> Liu, jiajun, et al. “Smart Grow-and-Twine Gripper for Vegetable Harvesting in Vertical Farms” <a href="https://doi.org/10.1109/RoboSoft60065.2024.10521949">2024 IEEE 7th International Conference on Soft Robotics (RoboSoft). IEEE, 2024.</a></p>

<hr />
<p><em>(c)  Pheelab. All rights reserved.</em></p>]]></content><author><name>Jiajun Liu</name></author><category term="Soft Robotics" /><category term="Force Sensor" /><summary type="html"><![CDATA[]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://pheelab.github.io/images/growtwine.jpg" /><media:content medium="image" url="https://pheelab.github.io/images/growtwine.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">low-cost magnet tracking device in confirming nasogastric tube placement</title><link href="https://pheelab.github.io/2024/02/25/ngt.html" rel="alternate" type="text/html" title="low-cost magnet tracking device in confirming nasogastric tube placement" /><published>2024-02-25T00:00:00+00:00</published><updated>2024-11-28T07:46:40+00:00</updated><id>https://pheelab.github.io/2024/02/25/ngt</id><content type="html" xml:base="https://pheelab.github.io/2024/02/25/ngt.html"><![CDATA[<figure class="figure">
  <img src="https://pheelab.github.io/images/ngt.jpg" alt="ngt" />
</figure>

<p>An affordable and reliable way of confirming the placement of nasogastric tube (NGT) at point-of-care is an unmet need. Using a novel algorithm and few sensors, we developed a low-cost magnet tracking device and showed its potential to localize the NGT preclinically. Here, we embark on a first-in-human trial. Six male and 4 female patients with NGT from the general ward of an urban hospital were recruited. We used the device to localize the NGT and compared that against chest X-ray (CXR). In 5 patients, with the sensors placed on the sternal angle, the trajectory of the NGT was reproduced by the tracking device. The tracked location of the NGT deviated from CXR by 0.55 to 1.63 cm, and a downward tracking range of 17 to 22 cm from the sternal angle was achieved. Placing the sensors on the xiphisternum, however, resulted in overt discordance between the device’s localization and that on CXR. Short distance between the sternal angle and the xiphisternum, and lower body weight were observed in patients in whom tracking was feasible. Tracking was quick and well tolerated. No adverse event occurred. This device feasibly localized the NGT in 50% of patients when appropriately placed. Further refinement is anticipated.</p>

<h3 id="related-pubulication">Related Pubulication:</h3>

<p class="box-note"><strong>Paper:</strong> Li, Hao, et al. “Feasibility of a low-cost magnet tracking device in confirming nasogastric tube placement at point of care, a clinical trial.” <a href="https://doi.org/10.1038/s41598-024-57455-7">Sci Rep 14, 7068 (2024).</a></p>

<hr />
<p><em>(c)  Pheelab. All rights reserved.</em></p>]]></content><author><name>Jiajun Liu</name></author><category term="Medical Devices" /><summary type="html"><![CDATA[]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://pheelab.github.io/images/ngt.jpg" /><media:content medium="image" url="https://pheelab.github.io/images/ngt.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Friction Modeling of Flexible Surgical Tools</title><link href="https://pheelab.github.io/2021/10/26/friction-modeling.html" rel="alternate" type="text/html" title="Friction Modeling of Flexible Surgical Tools" /><published>2021-10-26T00:00:00+00:00</published><updated>2024-11-28T07:46:40+00:00</updated><id>https://pheelab.github.io/2021/10/26/friction-modeling</id><content type="html" xml:base="https://pheelab.github.io/2021/10/26/friction-modeling.html"><![CDATA[<h3 id="a-frictional-contact-pattern-based-model-for-inserting-a-flexible-shaft-into-curved-channels">A Frictional Contact-Pattern-Based Model for Inserting a Flexible Shaft Into Curved Channels</h3>

<figure class="figure">
  <img src="https://pheelab.github.io/images/frictionmodeling.jpg" alt="Force sensor" />
</figure>

<p>Flexible endoscopy and catheterization typically involve inserting a flexible shaft into a curved channel. Understanding the mechanics involved in the insertion process is crucial for the structural design, actuation, sensing, control, and navigation of these flexible medical tools. However, the ever-changing contacts and friction between the insertion shaft and the pathway make the mechanics complicated. Existing analytical models simplify the problem by neglecting the friction and assuming specific boundary conditions that are valid only in a few specific instances. In the meantime, finite element method models have tradeoffs between computation speed, accuracy, and stability. This article presents an efficient theoretical framework to model the insertion process with friction, promoting fast and accurate computation of the mechanics involved. The inserting shaft is segmented based on the evolving contacts; system equations are formulated with friction-included force equilibrium and boundary conditions. The model is verified through experiments; channels with different shapes/curvatures were considered. The root-mean-square errors between the model and measured insertion forces are less than 0.055 N (average percentage error less than 9.62%). This model will enhance the fundamental understanding of the insertion process’s mechanics and benefit the engineering (design, actuation, and control) and medical practices of related medical tools (e.g., endoscopic instruments and catheters).</p>

<h3 id="related-pubulication">Related Pubulication:</h3>

<p class="box-note"><strong>Paper:</strong> Liu, Jiajun, et al. “A frictional contact-pattern-based model for inserting a flexible shaft into curved channels.”  <a href="https://doi.org/10.1109/TMECH.2021.3111701">IEEE/ASME Transactions on Mechatronics 27.5 (2021): 2556-2567.</a></p>

<hr />
<p><em>(c)  Pheelab. All rights reserved.</em></p>]]></content><author><name>Jiajun Liu</name></author><category term="Surgical Robotics" /><category term="Soft Robotics" /><summary type="html"><![CDATA[A Frictional Contact-Pattern-Based Model for Inserting a Flexible Shaft Into Curved Channels]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://pheelab.github.io/images/frictionmodeling.jpg" /><media:content medium="image" url="https://pheelab.github.io/images/frictionmodeling.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Flexible and Deployable Colon Support Structure for Endoluminal Interventions</title><link href="https://pheelab.github.io/2021/06/18/CSS.html" rel="alternate" type="text/html" title="Flexible and Deployable Colon Support Structure for Endoluminal Interventions" /><published>2021-06-18T00:00:00+00:00</published><updated>2024-11-28T07:46:40+00:00</updated><id>https://pheelab.github.io/2021/06/18/CSS</id><content type="html" xml:base="https://pheelab.github.io/2021/06/18/CSS.html"><![CDATA[<figure class="figure">
  <img src="https://pheelab.github.io/images/CSS.jpg" alt="Force sensor" />
</figure>

<p>When performing endoluminal surgery inside the colon using a flexible endoscopic robot, there is a problem of losing visualization and task space due to the collapsing of the surrounding wall. This happens mainly because of the intra-abdominal pressure and peristalsis of the colon. Although insufflation is commonly used for expanding the colon, it does not function when a full-thickness incision is created on the colon wall. To support the collapsing colon and ensure sufficient visualization and task space even with a hole, we developed a deployable colon support structure (CSS) that can be seamlessly adapted to the existing procedures. While the CSS is designed to be small and flexible enough to pass through an endoscopic channel that can be tortuous, it becomes sturdy enough to hold the collapsing/squeezing colon after being deployed. Also, the CSS is collapsible after task completion, for retraction through an endoscopic channel. Through the ex-vivo and in-vivo studies with a swine, we have successfully demonstrated the feasibility of supporting the colon wall during endoluminal interventions with the CSS. We confirmed that the CSS was easily deliverable and deployable and the created space was large enough to perform surgical tasks using robotic arms.</p>

<h3 id="related-pubulication">Related Pubulication:</h3>

<p class="box-note"><strong>Paper:</strong> M. Miyasaka et al. “Flexible and Deployable Colon Support Structure for Endoluminal Interventions.” <a href="https://doi.org/10.1109/ACCESS.2021.3090411">IEEE Access, vol. 9, pp. 91754-91763, 2021.</a></p>

<hr />
<p><em>(c)  Pheelab. All rights reserved.</em></p>]]></content><author><name></name></author><category term="Surgical Robotics" /><category term="Soft Robotics" /><summary type="html"><![CDATA[]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://pheelab.github.io/images/CSS.jpg" /><media:content medium="image" url="https://pheelab.github.io/images/CSS.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Robotic flexible endoscopic grasper with a three-axis force sensor</title><link href="https://pheelab.github.io/2021/04/06/force-sensor.html" rel="alternate" type="text/html" title="Robotic flexible endoscopic grasper with a three-axis force sensor" /><published>2021-04-06T00:00:00+00:00</published><updated>2024-11-28T07:46:40+00:00</updated><id>https://pheelab.github.io/2021/04/06/force-sensor</id><content type="html" xml:base="https://pheelab.github.io/2021/04/06/force-sensor.html"><![CDATA[<figure class="figure">
  <img src="https://pheelab.github.io/images/forcesensor2.jpg" alt="Force sensor" />
  <figcaption class="figure-caption">Force sensor integration with an articulated surgical gasper.</figcaption>
</figure>

<p>Haptic feedback is absent in flexible endoscopic surgical robots due to the size constraint of installing sensors on the small robotic arms. Besides, inherent hysteresis caused by the nonlinear friction between tendons and sheaths makes it hard to estimate the distal force by modeling. In this work, we addressed this challenge by proposing a new three-axial force sensor. This standalone device can be seamlessly integrated into the endoscopic robotic arm. Three optical fibers with fiber Bragg gratings (FBGs) are embedded in the sensing structure, where one is located at the center hole of the structure (ø 1.4 mm) and the other two are eccentrically placed around the structure at 90° apart from each other. This device can measure the pulling force and lateral forces of an articulated surgical instrument. Mechanics analysis has been studied to reveal the link between FBGs’ wavelength shifts and forces caused by the elongation and the bending with a temperature-compensation feature. The sensor has a lateral force sensitivity of 838.386 pm/N, with a measurement resolution of 1.19 mN. Performance comparison with a commercial force sensor Nano17 was made, with measurement errors from 4.50% to 6.18%. In the ex vivo tests, we teleoperated the sensorized grasper to pull, steer, and lift a piece of pig colon tissue. The tool–tissue interaction forces measured by the force sensor were displayed on the computer screen in real time. In addition to the endoscopic robots, the force sensor can also be integrated with other surgical robots such as laparoscopic robots and catheters.</p>

<h3 id="related-pubulication">Related Pubulication:</h3>

<p class="box-note"><strong>Paper:</strong> Lai, Wenjie, et al. “A Three-Axial Force Sensor Based on Fiber Bragg Gratings for Surgical Robots.”  <a href="https://ieeexplore.ieee.org/document/9397319"> IEEE/ASME Transactions on Mechatronics, vol. 27, no. 2, pp. 777-789</a></p>

<hr />
<p><em>(c)  Pheelab. All rights reserved.</em></p>]]></content><author><name>Wenjie Lai</name></author><category term="Surgical Robotics" /><category term="Force Sensor" /><summary type="html"><![CDATA[Force sensor integration with an articulated surgical gasper.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://pheelab.github.io/images/forcesensor.jpg" /><media:content medium="image" url="https://pheelab.github.io/images/forcesensor.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Sewing up the Wounds： A Robotic Suturing System for Flexible Endoscopy</title><link href="https://pheelab.github.io/2020/02/11/sewing-wounds.html" rel="alternate" type="text/html" title="Sewing up the Wounds： A Robotic Suturing System for Flexible Endoscopy" /><published>2020-02-11T00:00:00+00:00</published><updated>2024-11-28T07:46:40+00:00</updated><id>https://pheelab.github.io/2020/02/11/sewing-wounds</id><content type="html" xml:base="https://pheelab.github.io/2020/02/11/sewing-wounds.html"><![CDATA[<p><img src="https://pheelab.github.io/images/sewingup.jpg" alt="Crepe" class="mx-auto d-block" /></p>

<p>Perforations in the digestive tract are life-threatening, and that is why endoscopic physicians are very cautious when trying to remove cancerous tumors in the stomach or colon: they are afraid of cutting through the organs (i.e., perforations) and they do not have good tools to close the perforation. We developed a flexible endoscopic surgical robot to securely close the perforation by suturing - the gold standard of perforation closure. The tiny, dexterous robotic arms are inserted into the digestive tract via natural orifices (e.g., mouth or anus) and they are teleoperated by the clinician to repair the perforation. In this way, the clinician is able to close the perforation without opening up the patient’s body, a big advance compared to open surgery and laparoscopic surgery. Being able to suture perforations, the clinician can then cut deeper (more cleanly) when removing cancerous tumors that are deeply seeded in the digestive tract wall; he/she can even purposely make a hole on the stomach or colon to reach other organs outside for surgery on these organs; once done, the purposely created hole can then be sutured. This would promote a paradigm shift of current minimally invasive surgery from laparoscopic surgery to Natural Orifice Transluminal Endoscopic Surgery (NOTES) which promises scarless and faster recovery.</p>

<h3 id="related-pubulication">Related Pubulication:</h3>

<p class="box-note"><strong>Paper:</strong> Cao, Lin, et al. “Sewing up the wounds: A robotic suturing system for flexible endoscopy.” <a href="https://doi.org/10.1109/MRA.2019.2963161">IEEE Robotics &amp; Automation Magazine 27.3 (2020): 45-54.</a></p>

<hr />
<p><em>(c)  Pheelab. All rights reserved.</em></p>]]></content><author><name></name></author><category term="Surgical Robotics" /><summary type="html"><![CDATA[]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://pheelab.github.io/images/sewingup.jpg" /><media:content medium="image" url="https://pheelab.github.io/images/sewingup.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Magnet-actuated capsule for Weight Management</title><link href="https://pheelab.github.io/2020/01/01/magnet-capsule.html" rel="alternate" type="text/html" title="Magnet-actuated capsule for Weight Management" /><published>2020-01-01T00:00:00+00:00</published><updated>2024-11-28T07:46:40+00:00</updated><id>https://pheelab.github.io/2020/01/01/magnet-capsule</id><content type="html" xml:base="https://pheelab.github.io/2020/01/01/magnet-capsule.html"><![CDATA[<p><img src="https://pheelab.github.io/images/magnet.jpg" alt="Crepe" class="mx-auto d-block" /></p>

<p>Intragastric balloons (IGBs), by occupying the space in the stomach and prolonging satiety, is an established method to treat obesity and consequently improves its associated comorbidities, e.g. coronary heart disease, diabetes, and cancer. However, existing IGBs are often tethered with tubes for gas or liquid delivery or require endoscopic assistance for device delivery or removal, which are usually uncomfortable, costly, and may cause complications. We developed a novel tetherless, magnetically actuated capsule (EndoPil) which can deploy an IGB inside the stomach after being swallowed and being activated by an external magnet. The external magnet attracts a small magnet inside the EndoPil to open a valve, triggering the chemical reaction of citric acid and potassium bicarbonate to produce carbon dioxide gas, which inflates a biocompatible balloon (around 120 ml). A prototype, 13 mm in diameter and 35 mm in length, was developed. Simulations and bench-top tests were conducted to test the force capability of the magnetic actuation mechanism, the required force to activate the valve, and the repeatability of balloon inflation. Experiments on animal and human were successfully conducted to demonstrate the safety and feasibility of inflating a balloon inside the stomach by an external magnet.</p>

<h3 id="related-pubulication">Related Pubulication:</h3>

<p class="box-note"><strong>Paper:</strong> Phan, Phuoc Thien, et al. “EndoPil: A magnetically actuated swallowable capsule for weight management: Development and trials.” <a href="https://doi.org/10.1007/s10439-020-02692-w">Annals of Biomedical Engineering 49 (2021): 1391-1401.</a></p>

<p><strong>Paper:</strong> Do, Thanh Nho, et al. “A magnetic soft endoscopic capsule for non-surgical overweight and obese treatments.”  <a href="https://doi.org/10.1109/IROS.2016.7759372">2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, 2016.</a></p>

<p><strong>Paper:</strong> Do, Thanh Nho, et al. “A magnetic soft endoscopic capsule-inflated intragastric balloon for weight management.”  <a href="https://www.nature.com/articles/srep39486">Scientific reports 6.1 (2016): 39486.</a></p>

<p><strong>Paper:</strong> Do, Thanh Nho, et al. “Development and Testing of a Magnetically Actuated Capsule Endoscopy for Obesity Treatment.”  <a href="https://doi.org/10.1371/journal.pone.0148035">PloS one 11.1 (2016): e0148035.</a></p>

<hr />
<p><em>(c)  Pheelab. All rights reserved.</em></p>]]></content><author><name></name></author><category term="Surgical Robotics" /><summary type="html"><![CDATA[]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://pheelab.github.io/images/magnet.jpg" /><media:content medium="image" url="https://pheelab.github.io/images/magnet.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Foot-controlled Human-Machine Interface for Robotic Surgery</title><link href="https://pheelab.github.io/2019/01/08/foot-robot.html" rel="alternate" type="text/html" title="Foot-controlled Human-Machine Interface for Robotic Surgery" /><published>2019-01-08T00:00:00+00:00</published><updated>2024-11-28T07:46:40+00:00</updated><id>https://pheelab.github.io/2019/01/08/foot-robot</id><content type="html" xml:base="https://pheelab.github.io/2019/01/08/foot-robot.html"><![CDATA[<p><img src="https://pheelab.github.io/images/footinterface.jpg" alt="Crepe" class="mx-auto d-block" /></p>

<p>In most robotic flexible endoscopic systems, the endoscope and instruments are controlled separately by two operators, which may result in communication errors and inefficient operation. Our solution is to enable the surgeon to control both the endoscope and the instruments. We developed a novel teleoperation robotic endoscopic system commanded by one operator using the continuous and simultaneous movements of their two hands and one foot. This 13-degree-of-freedom (DoF) system integrates a foot-controlled robotic flexible endoscope and two hand-controlled robotic endoscopic instruments, a robotic grasper and a robotic cauterizing hook. A dedicated foot interface transfers the natural foot movements to the 4-DoF movements of the endoscope while two other commercial hand interfaces map the movements of the two hands to the two instruments individually. The foot-controlled interface can also be used to control industrial robotic arms by the foot.</p>

<h3 id="related-pubulication">Related Pubulication:</h3>

<p class="box-note"><strong>Paper:</strong> Huang, Yanpei, et al. “A three-limb teleoperated robotic system with foot control for flexible endoscopic surgery.”  <a href="https://link.springer.com/article/10.1007/s10439-021-02766-3">Annals of Biomedical Engineering 49 (2021): 2282-2296.</a></p>

<hr />
<h2 id="gallery">Gallery</h2>

<p><img src="https://pheelab.github.io/images/ex-vivo.jpg" alt="Ex-vivo test setup" /></p>
<center>Figure: Ex-vivo test setup. </center>

<hr />

<p><em>(c)  Pheelab. All rights reserved.</em></p>]]></content><author><name>Wenjie Lai</name></author><category term="Surgical Robotics" /><category term="Human-Machine Interface" /><summary type="html"><![CDATA[]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://pheelab.github.io/images/foot.jpg" /><media:content medium="image" url="https://pheelab.github.io/images/foot.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>